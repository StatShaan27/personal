<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Week-2 | Shaan</title>
  <link rel="stylesheet" href="../style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Playfair+Display&family=Inter:wght@300;500&display=swap" rel="stylesheet">
  <style>
    body {
      background-color: #121212;
      color: #e0e0e0;
      font-family: 'Inter', sans-serif;
      margin: 0;
      padding: 0;
    }

    h1, h2, h3, h4 {
      font-family: 'Playfair Display', serif;
      color: #6effe0;
    }

    header {
      text-align: center;
      padding: 2rem 1rem 1rem;
      background: #1e1e1e;
      border-bottom: 2px solid #333;
    }

    header nav ul {
      list-style: none;
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 1rem;
      padding: 0;
    }

    header nav ul li {
      display: inline;
    }

    header nav ul li a {
      text-decoration: none;
      color: #6effe0;
      font-weight: 500;
      border: 1px solid transparent;
      padding: 0.4rem 0.8rem;
      border-radius: 6px;
      transition: all 0.3s ease;
    }

    header nav ul li a:hover {
      border-color: #6effe0;
      background-color: #6effe0;
      color: #000;
    }

    .notes-wrapper {
      max-width: 900px;
      margin: 3rem auto;
      padding: 2rem;
      animation: fadeIn 1.2s ease;
    }

    .info-block {
      margin-bottom: 2rem;
      text-align: left;
      line-height: 1.6;
    }

    .info-block strong {
      color: #6effe0;
    }

    .toc {
      background-color: #1e1e1e;
      border-left: 4px solid #6effe0;
      padding: 1rem 1.5rem;
      margin-bottom: 2rem;
      border-radius: 8px;
    }

    .toc ul {
      padding-left: 1rem;
    }

    .toc ul li {
      padding: 0.3rem 0;
    }

    .toc a {
      color: #c9d1d9;
      text-decoration: none;
      border-bottom: 1px dashed #6effe0;
    }

    .toc a:hover {
      color: #6effe0;
    }

    .glow-box {
      border: 2px solid #6effe0;
      box-shadow: 0 0 20px rgba(110, 255, 224, 0.2);
      border-radius: 16px;
      padding: 2rem;
      margin-bottom: 2rem;
      background-color: #1e1e1e;
      animation: pulse 3s infinite ease-in-out;
    }

    @keyframes pulse {
      0%, 100% { box-shadow: 0 0 20px rgba(110, 255, 224, 0.2); }
      50% { box-shadow: 0 0 35px rgba(110, 255, 224, 0.4); }
    }

    ul {
      line-height: 1.6;
      padding-left: 1.2rem;
    }

    code, pre {
      background-color: #222;
      padding: 0.5rem 1rem;
      border-radius: 8px;
      font-family: monospace;
      color: #6effe0;
      display: block;
      overflow-x: auto;
    }

    .next-btn {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background-color: #6effe0;
      color: #000;
      padding: 0.6rem 1.2rem;
      border: none;
      border-radius: 8px;
      font-weight: bold;
      cursor: pointer;
      box-shadow: 0 0 10px #6effe0;
      transition: background-color 0.3s ease;
      z-index: 100;
    }


    .prev-btn {
    position: fixed;
    bottom: 20px;
    left: 20px;
    background-color: #6effe0;
    color: #000;
    border: none;
    padding: 0.6rem 1.2rem;
    border-radius: 8px;
    font-weight: bold
    cursor: pointer;
    box-shadow: 0 0 10px #6effe0;
    transition: background-color 0.3s ease;
    z-index: 100;
    }

    .next-btn:hover {
      background-color: #00ffcc;
    }

    .prev-btn:hover {
      background-color: #00ffcc;
    }

    footer {
      text-align: center;
      font-size: 0.9rem;
      color: #888;
      padding: 2rem 1rem;
    }
  </style>
  <script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

</head>
<body>

<header>
  <h1>Statistical Methods III: Week-2</h1>
  <p>AY 2025‚Äì26</p>
  <nav>
    <ul>
      <li><a href="../../index.html">Home</a></li>
      <li><a href="../../assets/Shaan_CV.pdf">CV</a></li>
      <li><a href="../../sections/projects.html">Projects</a></li>
      <li><a href="../../sections/education.html">Education</a></li>
      <li><a href="../../sections/misc.html">Misc</a></li>
    </ul>
  </nav>
</header>

<section class="notes-wrapper">

  <div class="info-block">
    <p><strong>Instructor:</strong> Debasis Sengupta </p>
    <p><strong>Office / Department:</strong> ASU</p>
    <p><strong>Email:</strong> sdebasis@isical.ac.in</p>
    <p><strong>Marking Scheme:</strong><br>
      Assignments: 20% | Midterm Test: 30% | End Semester: 50%
    </p>
  </div>

  <div class="toc">
    <h3>Contents</h3>
    <ul>
      <li><a href="#2.1"> Variance Inequality: Toward a General CRLB</a></li>
      <li><a href="#2.2"> Cram√©r‚ÄìRao Bound for IID Case</a></li>
      <li><a href="#2.3"> Summarising the simplifications</a></li>
      <li><a href="#2.4"> Cram√©r‚ÄìRao Inequality in the Discrete Case</a></li>
      <li><a href="#2.5">Fisher Information Identity</a></li>
      <li><a href="#2.6">Cram√©r‚ÄìRao Bound for Vector Parameters</a></li>
      <li><a href="#2.7">Fisher Information Matrix</a></li>
      <li><a href="#2.8">Cram√©r‚ÄìRao Lower Bound: Vector Parameter Case</a></li>
      <li><a href="#2.9">Information Equality and Fisher Information Identity</a></li>
      <li><a href="#2.10">Step-by-Step Breakdown: The Score Function</a></li>
      <li><a href="#2.11">Newton‚ÄìRaphson for MLE: Likelihood Maximization</a></li>
      <li><a href="#2.12">On the Direction of Steepest Ascent</a></li>
      <li><a href="#2.13">Connecting Fisher Information with the Hessian Matrix</a></li>
      <li><a href="#2.14">Geometry and Calculus Behind MLE</a></li>
      <li><a href="#2.15">Fisher‚Äôs Scoring Method</a></li>
      
    </ul>
  </div>

  <!-- Notes section boxes -->
  <div class="glow-box" id="2.1">
  <h4>üß† Variance Inequality: Toward a General CRLB</h4>
  <p>You‚Äôre discussing a <strong>variance inequality</strong> in estimation theory ‚Äî a generalized form of the <strong>Cram√©r‚ÄìRao bound</strong>.</p>

  <h4>üì¶ 1. Setup:</h4>
  <ul>
    <li>Let \( X_1, X_2, \dots, X_n \) be i.i.d. with density \( f(x|\theta) \).</li>
    <li>Let \( \mathbf{X} = (X_1, \dots, X_n) \) and \( W(\mathbf{X}) \) be any statistic.</li>
    <li>You aim to bound \( \operatorname{Var}_\theta(W(\mathbf{X})) \).</li>
  </ul>
  <p><strong>Key assumptions:</strong></p>
  <ul>
    <li>\( \operatorname{Var}_\theta(W(\mathbf{X})) < \infty \)</li>
    <li>\( \frac{d}{d\theta} \mathbb{E}_\theta[W(\mathbf{X})] = \int \frac{d}{d\theta} \left( W(\mathbf{X}) f(\mathbf{X}|\theta) \right) d\mathbf{x} \)</li>
  </ul>
  <p>The second condition is a <strong>regularity condition</strong> ‚Äî it lets you differentiate under the integral sign, essential for proving CR-type results.</p>

  <h4>üîé 2. The Inequality Itself:</h4>
  <p>Then, the variance of \( W(\mathbf{X}) \) satisfies the inequality:</p>
  \[
  \operatorname{Var}_\theta(W(\mathbf{X})) \geq \frac{ \left( \frac{d}{d\theta} \mathbb{E}_\theta[W(\mathbf{X})] \right)^2 }{ \mathbb{E}_\theta \left[ \left( \frac{d}{d\theta} \log f(\mathbf{X}|\theta) \right)^2 \right] }
  \]
  <p>This is a <strong>generalized Cram√©r‚ÄìRao Lower Bound</strong>.</p>
  <p>‚úÖ No matter what statistic or (nearly) unbiased estimator you use, its variance can‚Äôt fall below this bound.</p>

  <h4>‚ÑπÔ∏è Fisher Information</h4>
  <p>The denominator is the <strong>Fisher Information</strong>:</p>
  \[
  \mathcal{I}(\theta) := \mathbb{E}_\theta \left[ \left( \frac{d}{d\theta} \log f(\mathbf{X}|\theta) \right)^2 \right]
  \]
  <p>It quantifies how much information the sample \( \mathbf{X} \) provides about \( \theta \).</p>

  <h4>‚úÇÔ∏è 3. Simplification When Unbiased</h4>
  <p>If \( W(\mathbf{X}) \) is unbiased, i.e.</p>
  \[
  \mathbb{E}_\theta[W(\mathbf{X})] = \theta \quad \text{for all } \theta,
  \]
  <p>then:</p>
  \[
  \frac{d}{d\theta} \mathbb{E}_\theta[W(\mathbf{X})] = 1
  \]
  <p>This simplifies the variance bound to:</p>
  \[
  \operatorname{Var}_\theta(W(\mathbf{X})) \geq \frac{1}{\mathbb{E}_\theta \left[ \left( \frac{d}{d\theta} \log f(\mathbf{X}|\theta) \right)^2 \right]}
  \]
  <p>‚úÖ This is the <strong>standard Cram√©r‚ÄìRao Lower Bound</strong> for unbiased estimators.</p>

  <h4>üî¢ 4. Concrete Example</h4>
  <p>Suppose:</p>
  <ul>
    <li>\( \mathbb{E}(X_i) = \theta \) for all \( i \)</li>
    <li>Let \( W(\mathbf{X}) \) be the sample mean: \( \bar{X} = \frac{1}{n} \sum X_i \)</li>
  </ul>
  <p>Then clearly \( \mathbb{E}(W(\mathbf{X})) = \theta \), so this is an unbiased estimator.</p>
  <p>‚úÖ The simplified CRLB applies.</p>

  <h4>üìå Summary So Far:</h4>
  <ul>
    <li>A general inequality relates the <strong>variance</strong> of an estimator to the <strong>sensitivity of its expectation</strong> and the <strong>Fisher Information</strong>.</li>
    <li>Under mild conditions, the inequality holds broadly.</li>
    <li>If the estimator is <strong>unbiased</strong>, the bound takes a cleaner form.</li>
    <li><strong>Example:</strong> Sample mean of i.i.d. data with mean \( \theta \) satisfies the CRLB conditions.</li>
  </ul>
</div>












    <div class="glow-box" id="2.2">
  <h4>üîç Simplification (2): Cram√©r‚ÄìRao Bound for IID Case</h4>

  <h4>üß© 1. Factorization of Likelihood for IID Samples</h4>
  <p>If \( X_1, \dots, X_n \) are <strong>i.i.d.</strong>, then:</p>
  \[
  f(\mathbf{x}|\theta) = \prod_{i=1}^{n} f(x_i|\theta)
  \quad \Rightarrow \quad
  \log f(\mathbf{x}|\theta) = \sum_{i=1}^{n} \log f(x_i|\theta)
  \]
  <p>This simplifies the <strong>log-likelihood</strong> and makes computing the <strong>score function</strong> much easier.</p>

  <h4>üìò 2. Example: \( X_i \sim \mathcal{N}(\mu, 1) \)</h4>
  <p>The density is:</p>
  \[
  f(x_i|\mu) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{(x_i - \mu)^2}{2}\right)
  \]
  <p>Then the log-likelihood becomes:</p>
  \[
  \log f(x_i|\mu) = -\frac{1}{2} \log(2\pi) - \frac{1}{2}(x_i - \mu)^2
  \]
  <p>Differentiating with respect to \( \mu \):</p>
  \[
  \frac{d}{d\mu} \log f(x_i|\mu) = x_i - \mu
  \]
  <p>So, the <strong>score function for the full sample</strong> is:</p>
  \[
  \frac{d}{d\mu} \log f(\mathbf{x}|\mu) = \sum_{i=1}^n (x_i - \mu)
  \]

  <h4>üìê 3. Fisher Information</h4>
  <p>To compute the <strong>Fisher Information</strong> \( \mathcal{I}(\mu) \), we evaluate:</p>
  \[
  \mathbb{E}_\mu \left[ \left( \sum_{i=1}^n (X_i - \mu) \right)^2 \right]
  \]
  <p>Because the \( X_i \) are independent and each has zero mean after centering:</p>
  \[
  = \sum_{i=1}^n \mathbb{E}_\mu[(X_i - \mu)^2]
  \]
  <p>Each term \( \mathbb{E}_\mu[(X_i - \mu)^2] = 1 \), so total Fisher Information is:</p>
  \[
  \mathcal{I}(\mu) = n
  \]

  <h4>‚úÖ Conclusion: CRLB Achieved by Sample Mean</h4>
  <ul>
    <li><strong>Estimator:</strong> Sample mean \( \bar{X} \)</li>
    <li><strong>Unbiased:</strong> Yes</li>
    <li><strong>Variance of \( \bar{X} \):</strong> \( \frac{1}{n} \)</li>
    <li><strong>Fisher Information:</strong> \( n \)</li>
    <li><strong>CRLB:</strong> \( \frac{1}{n} \)</li>
  </ul>
  <p>‚úÖ The sample mean <em>achieves</em> the bound, hence it is <strong>efficient</strong>.</p>
</div>
















    

  <div class="glow-box" id="2.3">
  <h4>‚úÖ Putting It All Together</h4>
  <p>You've now made two key simplifications:</p>

  <h4>Simplification (1)</h4>
  <p>If \(\mathbb{E}_\mu[W(\mathbf{X})] = \mu\), then:</p>
  <ul>
    <li>\(W(\mathbf{X})\) is an <strong>unbiased</strong> estimator of \(\mu\)</li>
    <li>So, numerator in CRLB becomes 1</li>
  </ul>
  <p>
    \[
    \operatorname{Var}_\mu(W(\mathbf{X})) \geq \frac{1}{\mathbb{E}_\mu\left[ \left( \frac{d}{d\mu} \log f(\mathbf{X}|\mu) \right)^2 \right]} = \frac{1}{\text{Fisher Information}}
    \]
  </p>

  <h4>Simplification (2)</h4>
  <p>For the i.i.d. normal case:</p>
  <ul>
    <li>The Fisher Information = \(n\)</li>
    <li>So CRLB = \(\frac{1}{n}\)</li>
  </ul>

  <h4>‚ùì Immediate Question: Does the sample mean attain this lower bound?</h4>
  <p>Let‚Äôs answer it clearly.</p>
  <ul>
    <li>The sample mean is: 
      \[
      \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i
      \]
    </li>
    <li>Since \(X_i \sim \mathcal{N}(\mu, 1)\), by standard properties:
      \[
      \mathbb{E}[\bar{X}] = \mu, \quad \operatorname{Var}(\bar{X}) = \frac{1}{n}
      \]
    </li>
  </ul>
  <p>‚úÖ So the sample mean:</p>
  <ul>
    <li><strong>Is unbiased</strong>: satisfies Simplification (1)</li>
    <li><strong>Has variance \(\frac{1}{n}\)</strong>: exactly equals the CRLB from Simplification (2)</li>
  </ul>

  <h4>‚úÖ Final Answer</h4>
  <p><strong>Yes</strong>, the sample mean <strong>attains the Cram√©r‚ÄìRao lower bound</strong> in this case. Hence, it is an <strong>efficient estimator</strong> of \(\mu\) for the normal model with known variance.</p>


</div>



















    
<div class="glow-box" id="2.4">
  <h4>üîÅ Cram√©r‚ÄìRao Inequality in the Discrete Case</h4>
  <p>You're now pointing toward the <strong>discrete version</strong> of the Cram√©r‚ÄìRao bound, where we deal with <strong>PMFs</strong> instead of PDFs.</p>
  <p>Let‚Äôs go through this step-by-step.</p>

  <h4>üì¶ Now in the discrete case:</h4>
  <p>Instead of a pdf \( f(x|\theta) \), you have a <strong>pmf</strong> \( p(x|\theta) \), where \( x \in \mathcal{X} \), a countable set.</p>

  <h4>üß† Key Result:</h4>
  <p>Suppose:</p>
  <ul>
    <li>\( X_1, \dots, X_n \) are i.i.d. with <strong>pmf</strong> \( p(x|\theta) \)</li>
    <li>\( W(\mathbf{X}) \) is a statistic satisfying:
      <ul>
        <li>\( \mathbb{E}_\theta[W(\mathbf{X})] \) is <strong>differentiable</strong></li>
        <li>The derivative of expectation can be interchanged with the sum:
          \[
          \frac{d}{d\theta} \mathbb{E}_\theta[W(\mathbf{X})] = \sum_{\mathbf{x}} W(\mathbf{x}) \frac{d}{d\theta} p(\mathbf{x}|\theta)
          \]
        </li>
      </ul>
    </li>
  </ul>

  <p>Then, the <strong>Cram√©r‚ÄìRao-type inequality</strong> holds:</p>
  <p>
    \[
    \operatorname{Var}_\theta(W(\mathbf{X})) \geq 
    \frac{\left( \frac{d}{d\theta} \mathbb{E}_\theta[W(\mathbf{X})] \right)^2}{
    \mathbb{E}_\theta\left[ \left( \frac{d}{d\theta} \log p(\mathbf{X}|\theta) \right)^2 \right]}
    \]
  </p>
  <p>This is structurally identical to the continuous case ‚Äî but all integrals are now <strong>sums</strong> over discrete outcomes.</p>

  <h4>‚úÖ Example: Bernoulli Case</h4>
  <p>Let‚Äôs make this real.</p>
  <ul>
    <li>\( X_1, \dots, X_n \sim \text{Bernoulli}(p) \)</li>
    <li>\( p \in (0, 1) \), the parameter to estimate</li>
    <li>\( \mathbf{X} = (X_1, \dots, X_n) \)</li>
  </ul>

  <ul>
    <li>PMF: \( p(x_i | p) = p^{x_i}(1-p)^{1 - x_i} \)</li>
    <li>Log-likelihood:
      \[
      \log p(\mathbf{X}|p) = \sum_{i=1}^n \left[ x_i \log p + (1 - x_i) \log(1 - p) \right]
      \]
    </li>
    <li>Score:
      \[
      \frac{d}{dp} \log p(\mathbf{X}|p) = \sum_{i=1}^n \left( \frac{x_i}{p} - \frac{1 - x_i}{1 - p} \right)
      \]
    </li>
    <li>Fisher Information:
      \[
      \mathcal{I}(p) = \mathbb{E}_p\left[ \left( \sum_{i=1}^n \left( \frac{X_i}{p} - \frac{1 - X_i}{1 - p} \right) \right)^2 \right] = \frac{n}{p(1 - p)}
      \]
    </li>
    <li>Sample mean \( \bar{X} = \frac{1}{n} \sum X_i \) is unbiased</li>
    <li>Its variance: \( \frac{p(1 - p)}{n} \)</li>
  </ul>

  <p>Then CRLB is:</p>
  <p>
    \[
    \operatorname{Var}(\hat{p}) \geq \frac{1}{\mathcal{I}(p)} = \frac{p(1 - p)}{n}
    \]
  </p>
  <p>‚úÖ The sample mean attains this ‚Üí it is efficient.</p>

  <h4>üìå Summary</h4>
  <ul>
    <li>The CRLB works <strong>analogously</strong> for <strong>discrete pmfs</strong></li>
    <li>Replace integrals with sums</li>
    <li>Use \( \log p(x|\theta) \) instead of \( \log f(x|\theta) \)</li>
    <li>Example: Bernoulli trials ‚Üí sample mean of i.i.d. Bernoulli ‚áí efficient estimator of \( p \)</li>
  </ul>
</div>


















    

  <div class="glow-box" id="2.5">
  <h4>üìò Fisher Information Identity</h4>
  <p>We now state a very important identity in statistical inference ‚Äî the <strong>Fisher Information identity</strong>, which links the <strong>variance of the score</strong> with the <strong>expected second derivative of the log-likelihood</strong>.</p>
  <p>Let‚Äôs unpack it clearly.</p>

  <h4>üìò Statement of the Result:</h4>
  <p>If the regularity condition holds:</p>
  <p>
    \[
    \frac{d}{d\theta}\mathbb{E}_{\theta}\left(\frac{\partial}{\partial\theta}\log f(X|\theta)\right) = 
    \int \left[\frac{\partial}{\partial\theta}\left[\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right) f(x|\theta)\right]\right] dx,
    \]
  </p>
  <p>then we can derive:</p>
  <p>
    \[
    \mathbb{E}_\theta\left[\left(\frac{\partial}{\partial\theta} \log f(X|\theta)\right)^2\right] = 
    -\mathbb{E}_\theta\left[\frac{\partial^2}{\partial\theta^2} \log f(X|\theta)\right]
    \]
  </p>
  <p>This is known as the <strong>Fisher Information equality</strong>, and both sides equal the <strong>Fisher Information</strong> \( \mathcal{I}(\theta) \).</p>

  <h4>üìå Why This Is True: Key Insight</h4>
  <p>Let \( \ell(\theta; X) = \log f(X|\theta) \), the log-likelihood. Then:</p>
  <ul>
    <li><strong>Score:</strong> \( \frac{\partial}{\partial\theta} \ell(\theta; X) \)</li>
    <li><strong>Expectation of the score:</strong>
      \[
      \mathbb{E}_\theta\left[\frac{\partial}{\partial\theta} \ell(\theta; X)\right] = 0
      \]
      (as long as the pdf is regular enough and integrates to 1)
    </li>
  </ul>
  <p>Differentiate under the integral sign:</p>
  <p>
    \[
    \frac{d}{d\theta} \mathbb{E}_\theta\left[\frac{\partial}{\partial\theta} \ell(\theta; X)\right] = 0 =
    \mathbb{E}_\theta\left[ \frac{\partial^2}{\partial\theta^2} \ell(\theta; X) + 
    \left( \frac{\partial}{\partial\theta} \ell(\theta; X) \right)^2 \right]
    \]
  </p>
  <p>Rearranged:</p>
  <p>
    \[
    \mathbb{E}_\theta\left[\left(\frac{\partial}{\partial\theta} \log f(X|\theta)\right)^2\right] =
    -\mathbb{E}_\theta\left[\frac{\partial^2}{\partial\theta^2} \log f(X|\theta)\right]
    \]
  </p>

  <h4>üîÅ Interpretation</h4>
  <ul>
    <li>LHS = variance of the score (square of derivative of log-likelihood)</li>
    <li>RHS = negative expectation of the second derivative (curvature of log-likelihood)</li>
  </ul>
  <p>Both quantify <strong>how much information</strong> the data contains about \( \theta \).</p>

  <h4>‚úÖ Summary</h4>
  <p>You‚Äôre stating the <strong>Fisher Information identity</strong>, which tells us:</p>
  <blockquote>
    Under regularity conditions, the variance of the score function equals the negative expected second derivative of the log-likelihood.
  </blockquote>
  <p>
    \[
    \mathcal{I}(\theta) = \operatorname{Var}_\theta\left( \frac{d}{d\theta} \log f(X|\theta) \right) =
    -\mathbb{E}_\theta\left[ \frac{d^2}{d\theta^2} \log f(X|\theta) \right]
    \]
  </p>
  <p>This is foundational in deriving the <strong>Cram√©r‚ÄìRao Lower Bound</strong>, and in <strong>asymptotic theory</strong> (MLE consistency and normality).</p>

</div>























<div class="glow-box" id="2.6">
  <section>
  <h4>üß† Cram√©r‚ÄìRao Bound for Vector Parameters</h4>
  <p>
    Excellent ‚Äî you‚Äôre now stepping into the <strong>multivariate (vector parameter) version</strong> 
    of the Cram√©r‚ÄìRao Lower Bound (CRLB), which generalizes the scalar case using 
    <strong>matrix calculus and Fisher information matrices</strong>.
  </p>
  <p>Let‚Äôs break it down.</p>
  <hr>

  <p>Let:</p>
  <ul>
    <li><span>\(\boldsymbol{\theta} \in \mathbb{R}^k\)</span>: vector parameter</li>
    <li><span>\(\mathbf{X} \sim f(\mathbf{x}|\boldsymbol{\theta})\)</span></li>
    <li><span>\(\mathbf{W}(\mathbf{X}) \in \mathbb{R}^m\)</span>: vector-valued statistic</li>
    <li><span>\(\mathbf{W}(\mathbf{X})\)</span> has finite variance and differentiable expectation w.r.t. <span>\(\boldsymbol{\theta}\)</span></li>
  </ul>

  <h4>üìò Multivariate CRLB (Matrix Form):</h4>
  <div class="math">
    \[
    \operatorname{Var}_{\boldsymbol{\theta}}(\mathbf{W}(\mathbf{X})) \succeq 
    \left( \frac{d}{d\boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] \right)^\top 
    \cdot \mathcal{I}(\boldsymbol{\theta})^{-1} \cdot 
    \left( \frac{d}{d\boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] \right)
    \]
  </div>

  <h4>üìå Notation Breakdown:</h4>
  <ul>
    <li><span>\(\operatorname{Var}_{\boldsymbol{\theta}}(\mathbf{W}) \in \mathbb{R}^{m \times m}\)</span>: Covariance matrix of the estimator</li>
    <li><span>\(\frac{d}{d\boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}] \in \mathbb{R}^{m \times k}\)</span>: Jacobian matrix of expectation</li>
    <li><span>\(\mathcal{I}(\boldsymbol{\theta}) \in \mathbb{R}^{k \times k}\)</span>: Fisher Information matrix</li>
    <li><span>\(\succeq\)</span>: Matrix inequality meaning the difference is positive semi-definite</li>
  </ul>

  <h4>‚öôÔ∏è Meaning:</h4>
  <p>
    This inequality tells you that the <strong>covariance matrix of any estimator</strong> 
    of a vector parameter is bounded <strong>from below</strong> by a matrix formed from:
  </p>
  <ul>
    <li>The sensitivity of the estimator (Jacobian of expectation)</li>
    <li>The inverse Fisher Information matrix</li>
  </ul>

  <h4>‚úÖ Special Case: Unbiased Estimator</h4>
  <p>If <span>\(\mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] = \boldsymbol{\theta}\)</span>, then:</p>
  <ul>
    <li>Jacobian = Identity matrix <span>\(I_k\)</span></li>
  </ul>
  <p>So, the bound becomes:</p>
  <div class="math">
    \[
    \operatorname{Var}_{\boldsymbol{\theta}}(\mathbf{W}(\mathbf{X})) \succeq \mathcal{I}(\boldsymbol{\theta})^{-1}
    \]
  </div>
  <p>Just like in the scalar case, but extended to full matrix structure.</p>
</section>

</div>
















































<div class="glow-box" id="2.7">
  <section>
  <h4>üìò Fisher Information Matrix \(\mathcal{I}(\boldsymbol{\theta})\)</h4>
  <p>Let‚Äôs now define the <strong>Fisher Information Matrix</strong> \(\mathcal{I}(\boldsymbol{\theta})\) in the <strong>vector parameter</strong> case.</p>
  <hr>

  <p>Let:</p>
  <ul>
    <li>\(\boldsymbol{\theta} \in \mathbb{R}^k\): vector parameter</li>
    <li>\(\mathbf{X} \sim f(\mathbf{x} | \boldsymbol{\theta})\)</li>
    <li>Assume \(f(\mathbf{x} | \boldsymbol{\theta})\) satisfies suitable <strong>regularity conditions</strong> (e.g., to allow differentiation under the integral)</li>
  </ul>

  <h4>‚úÖ The Fisher Information Matrix is defined as:</h4>
  \[
  \mathcal{I}(\boldsymbol{\theta}) = \mathbb{E}_{\boldsymbol{\theta}} \left[ \left( \nabla_{\boldsymbol{\theta}} \log f(\mathbf{X}|\boldsymbol{\theta}) \right) \left( \nabla_{\boldsymbol{\theta}} \log f(\mathbf{X}|\boldsymbol{\theta}) \right)^\top \right]
  \]

  <h4>üîç Where:</h4>
  <ul>
    <li>\(\nabla_{\boldsymbol{\theta}} \log f(\mathbf{X}|\boldsymbol{\theta}) \in \mathbb{R}^k\): the <strong>score vector</strong>
      \[
      \nabla_{\boldsymbol{\theta}} \log f(\mathbf{X}|\boldsymbol{\theta}) =
      \begin{bmatrix}
      \frac{\partial}{\partial\theta_1} \log f(\mathbf{X}|\boldsymbol{\theta}) \\
      \vdots \\
      \frac{\partial}{\partial\theta_k} \log f(\mathbf{X}|\boldsymbol{\theta})
      \end{bmatrix}
      \]
    </li>
    <li>The outer product produces a \(k \times k\) matrix</li>
    <li>So, the Fisher Information Matrix is a <strong>positive semi-definite</strong> matrix of size \(k \times k\)</li>
  </ul>

  <h4>üß† Alternate Form (if second derivatives are easier to compute):</h4>
  <p>Under stronger regularity conditions, we can also write:</p>
  \[
  \mathcal{I}(\boldsymbol{\theta}) = -\mathbb{E}_{\boldsymbol{\theta}} \left[ \nabla_{\boldsymbol{\theta}}^2 \log f(\mathbf{X}|\boldsymbol{\theta}) \right]
  \]
  <p>Here, \(\nabla_{\boldsymbol{\theta}}^2 \log f(\mathbf{X}|\boldsymbol{\theta}) \in \mathbb{R}^{k \times k}\) is the <strong>Hessian matrix</strong> of second-order partial derivatives.</p>
</section>

</div>











































<div class="glow-box" id="2.8">
  <section>
  <h4>üß† Cram√©r‚ÄìRao Lower Bound: Vector Parameter Case</h4>
  <p>Here's the <strong>full form of the Cram√©r‚ÄìRao Lower Bound (CRLB)</strong> in the vector parameter case, complete with all definitions, assumptions, and mathematical structure.</p>
  <hr>

  <p>Let:</p>
  <ul>
    <li>\(\boldsymbol{\theta} \in \mathbb{R}^k\): vector-valued parameter</li>
    <li>\(\mathbf{X} \in \mathbb{R}^n\): random sample with joint pdf (or pmf) \(f(\mathbf{x} | \boldsymbol{\theta})\)</li>
    <li>\(\mathbf{W}(\mathbf{X}) \in \mathbb{R}^m\): statistic estimating a function of \(\boldsymbol{\theta}\)</li>
    <li>All relevant expectations, gradients, and Fisher Information are well-defined and finite</li>
  </ul>

  <h4>üìò General Matrix Form of the CRLB:</h4>
  \[
  \operatorname{Cov}_{\boldsymbol{\theta}}(\mathbf{W}(\mathbf{X})) \succeq 
  \left( \frac{\partial}{\partial \boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] \right)
  \cdot \mathcal{I}(\boldsymbol{\theta})^{-1} \cdot 
  \left( \frac{\partial}{\partial \boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] \right)^\top
  \]

  <h4>üß© Term Definitions:</h4>
  <ul>
    <li>\(\operatorname{Cov}_{\boldsymbol{\theta}}(\mathbf{W}) \in \mathbb{R}^{m \times m}\): Covariance matrix of the estimator</li>
    <li>\(\frac{\partial}{\partial \boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}] \in \mathbb{R}^{m \times k}\): Jacobian matrix of expected estimator wrt \(\boldsymbol{\theta}\)</li>
    <li>\(\mathcal{I}(\boldsymbol{\theta}) \in \mathbb{R}^{k \times k}\): Fisher Information Matrix</li>
  </ul>

  <h4>üéØ Fisher Information Matrix Definition:</h4>
  <p>Let the <strong>score vector</strong> be:</p>
  \[
  \mathbf{S}(\mathbf{X}; \boldsymbol{\theta}) = \nabla_{\boldsymbol{\theta}} \log f(\mathbf{X} | \boldsymbol{\theta}) \in \mathbb{R}^k
  \]
  <p>Then:</p>
  \[
  \mathcal{I}(\boldsymbol{\theta}) = \mathbb{E}_{\boldsymbol{\theta}}\left[ \mathbf{S}(\mathbf{X}; \boldsymbol{\theta}) \mathbf{S}(\mathbf{X}; \boldsymbol{\theta})^\top \right]
  \]
  <p>Or, under regularity conditions:</p>
  \[
  \mathcal{I}(\boldsymbol{\theta}) = - \mathbb{E}_{\boldsymbol{\theta}}\left[ \nabla_{\boldsymbol{\theta}}^2 \log f(\mathbf{X} | \boldsymbol{\theta}) \right]
  \]

  <h4>‚úÖ Special Case: Unbiased Estimator</h4>
  <p>If \(\mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] = \boldsymbol{\theta}\), then the Jacobian is identity, and:</p>
  \[
  \operatorname{Cov}_{\boldsymbol{\theta}}(\mathbf{W}) \succeq \mathcal{I}(\boldsymbol{\theta})^{-1}
  \]
  <p>This matches the scalar case:</p>
  \[
  \operatorname{Var}_{\theta}(W) \geq \frac{1}{\mathcal{I}(\theta)}
  \]

  <h4>üß† Setup: Vector CRLB with Fisher Info Substituted</h4>
  <ul>
    <li>\(\boldsymbol{\theta} \in \mathbb{R}^p\): vector parameter</li>
    <li>\(\mathbf{X}\): data with PDF/PMF \(f(\mathbf{x}|\boldsymbol{\theta})\)</li>
    <li>\(\mathbf{W}(\mathbf{X}) \in \mathbb{R}^k\): unbiased estimator of \(\boldsymbol{\psi}(\boldsymbol{\theta}) = \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})]\)</li>
  </ul>

  <h4>‚úÖ CRLB (Multivariate Version):</h4>
  \[
  \text{Cov}_{\boldsymbol{\theta}}(\mathbf{W}(\mathbf{X})) \succeq
  \left[ \frac{ \partial \boldsymbol{\psi}(\boldsymbol{\theta}) }{ \partial \boldsymbol{\theta} } \right]^\top
  \left[ \mathbb{E}_{\boldsymbol{\theta}} \left[
    \left( \frac{ \partial }{ \partial \boldsymbol{\theta} } \log f(\mathbf{X}|\boldsymbol{\theta}) \right)
    \left( \frac{ \partial }{ \partial \boldsymbol{\theta} } \log f(\mathbf{X}|\boldsymbol{\theta}) \right)^\top
  \right] \right]^{-1}
  \left[ \frac{ \partial \boldsymbol{\psi}(\boldsymbol{\theta}) }{ \partial \boldsymbol{\theta} } \right]
  \]

  <h4>üîç Explanation of Components:</h4>
  <ul>
    <li>\(\frac{ \partial \boldsymbol{\psi}(\boldsymbol{\theta}) }{ \partial \boldsymbol{\theta} } \in \mathbb{R}^{k \times p}\): Jacobian of \(\boldsymbol{\psi}(\boldsymbol{\theta})\)</li>
    <li>Middle matrix is the <strong>Fisher Information Matrix</strong>:
      \[
      \mathbf{I}(\boldsymbol{\theta}) =
      \mathbb{E}_{\boldsymbol{\theta}} \left[
        \left( \frac{ \partial }{ \partial \boldsymbol{\theta} } \log f(\mathbf{X}|\boldsymbol{\theta}) \right)
        \left( \frac{ \partial }{ \partial \boldsymbol{\theta} } \log f(\mathbf{X}|\boldsymbol{\theta}) \right)^\top
      \right]
      \]
    </li>
  </ul>

  <h4>üìå Summary:</h4>
  <p>The multivariate CRLB states:</p>
  \[
  \boxed{
  \text{Cov}_{\boldsymbol{\theta}}(\mathbf{W}(\mathbf{X})) \succeq
  \left[ \frac{ \partial \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] }{ \partial \boldsymbol{\theta} } \right]^\top
  \left[
  \mathbb{E}_{\boldsymbol{\theta}} \left[
    \left( \frac{ \partial }{ \partial \boldsymbol{\theta} } \log f(\mathbf{X}|\boldsymbol{\theta}) \right)
    \left( \frac{ \partial }{ \partial \boldsymbol{\theta} } \log f(\mathbf{X}|\boldsymbol{\theta}) \right)^\top
  \right]
  \right]^{-1}
  \left[ \frac{ \partial \mathbb{E}_{\boldsymbol{\theta}}[\mathbf{W}(\mathbf{X})] }{ \partial \boldsymbol{\theta} } \right]
  }
  \]
  <p>This is a <strong>matrix inequality</strong>: the LHS is the covariance matrix of the estimator, and the RHS is the lower bound (in the <strong>positive semi-definite</strong> sense).</p>
</section>

</div>
































<div class="glow-box" id="2.9">
  <section>
  <h4>‚ú® Information Equality and Fisher Information Identity</h4>
  <p>You're diving into the <strong>information equality</strong> result, which is foundational for the <strong>Cram√©r‚ÄìRao lower bound (CRLB)</strong>. It links the <strong>variance of the score function</strong> with the <strong>expected curvature</strong> of the log-likelihood.</p>
  <hr>
  <p>Let us go through each step in full clarity, with notation, interpretation, and a diagram at the end.</p>

  <h4>üî∂ The Setup</h4>
  <ul>
    <li> \( f(x \mid \theta) \) : parametric family of densities</li>
    <li>Regularity conditions assumed (interchanging integration and differentiation allowed)</li>
    <li>\( x \) is a random variable drawn from $f(x \mid \theta)$</li>
    <li> \( \theta \in \mathbb{R} \): scalar parameter</li>
  </ul>

  <h4>üß∞ Step 1: Expectation of the Score Function is Zero</h4>
  \[
  \mathbb{E}_\theta\left[ \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right] = 0
  \]
  <p>This is a standard identity under regularity conditions:</p>
  \[
  \begin{align*}
  \mathbb{E}_\theta\left[ \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right]
  &= \int \frac{\partial}{\partial \theta} \log f(x \mid \theta) \cdot f(x \mid \theta)\, dx \\
  &= \int \frac{1}{f(x \mid \theta)} \cdot \frac{\partial f(x \mid \theta)}{\partial \theta} \cdot f(x \mid \theta)\, dx \\
  &= \int \frac{\partial f(x \mid \theta)}{\partial \theta} \, dx \\
  &= \frac{\partial}{\partial \theta} \int f(x \mid \theta) \, dx = \frac{\partial}{\partial \theta}(1) = 0
  \end{align*}
  \]
  <p><strong>Conclusion:</strong> the expected score is zero.</p>

  <h4>üîπ Step 2: Variance of Score Function = Negative Expectation of Second Derivative</h4>
  <p>The claim is:</p>
  \[
  \mathbb{E}_\theta\left[ \left( \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right)^2 \right] = 
  - \mathbb{E}_\theta\left[ \frac{\partial^2}{\partial \theta^2} \log f(x \mid \theta) \right]
  \]

  <h4>üìå LHS: Variance of the Score Function</h4>
  \[
  \begin{align*}
  \mathbb{E}_\theta\left[ \left( \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right)^2 \right]
  &= \int \left( \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right)^2 f(x \mid \theta)\, dx \\
  &= \int \left( \frac{ \partial f(x \mid \theta)/\partial \theta }{ f(x \mid \theta) } \right)^2 f(x \mid \theta)\, dx \\
  &= \int \left( \frac{ \partial f(x \mid \theta) }{ \partial \theta } \right)^2 \cdot \frac{1}{f(x \mid \theta)}\, dx
  \end{align*}
  \]

  <h4>üìå RHS: Negative Expectation of Second Derivative</h4>
  \[
  \begin{align*}
  \mathbb{E}_\theta\left[ \frac{\partial^2}{\partial \theta^2} \log f(x \mid \theta) \right]
  &= \int \frac{\partial^2}{\partial \theta^2} \log f(x \mid \theta) \cdot f(x \mid \theta)\, dx \\
  &= \int \left[ \frac{ \partial^2 f }{ \partial \theta^2 } - \frac{ (\partial f/\partial \theta)^2 }{ f } \right] dx
  \end{align*}
  \]
  <p>Now, under regularity:</p>
  \[
  \int \frac{\partial^2 f(x \mid \theta)}{\partial \theta^2} dx = \frac{\partial^2}{\partial \theta^2} 1 = 0
  \]
  <p>So the result becomes:</p>
  \[
  - \int \frac{ (\partial f / \partial \theta)^2 }{ f } dx
  \]
  <p><strong>Conclusion:</strong></p>
  \[
  \mathbb{E}_\theta\left[ \left( \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right)^2 \right] = - \mathbb{E}_\theta\left[ \frac{\partial^2}{\partial \theta^2} \log f(x \mid \theta) \right]
  \]

  <h4>üìä Visual Interpretation</h4>
  <p>Let \( \ell(\theta) = \log f(x \mid \theta) \). Then:</p>
  <ul>
    <li>\( \ell'(\theta) \): score function ‚Äî slope of log-likelihood</li>
    <li>\( \ell''(\theta) \): curvature ‚Äî measures peakness/flatness</li>
    <li>Taking expectation, the curvature = variance of slope (negated)</li>
  </ul>

  <h4>‚Ñπ Fisher Information</h4>
  \[
  \mathcal{I}(\theta) = \mathbb{E}_\theta\left[ \left( \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right)^2 \right] = -\mathbb{E}_\theta\left[ \frac{\partial^2}{\partial \theta^2} \log f(x \mid \theta) \right]
  \]
  <p>This quantifies how much information one observation gives about \(\theta\).</p>

  <h4>üìÜ Summary</h4>
  <ul>
    <li>This is the <strong>Fisher Information identity</strong></li>
    <li>Backbone of the <strong>Cram√©r‚ÄìRao Inequality</strong></li>
    <li>Relies on <strong>regularity conditions</strong> (to switch integral and derivative)</li>
    <li>Captures the connection between score and curvature</li>
  </ul>
</section>
</div>
























<div class="glow-box" id="2.10">
  <section>
  <h4>üî∑ Step-by-Step Breakdown: The Score Function</h4>
  <p>Let‚Äôs walk through it clearly, with <strong>intuition</strong>, <strong>derivation</strong>, and a <strong>small example</strong>.</p>
  <hr>

  <h4>üìò Log-Likelihood Expression</h4>
  <p>You wrote:</p>
  \[
  L(\theta \mid x_1, x_2, \dots, x_n) = \sum_{i=1}^n \log f(x_i \mid \theta)
  \]
  <p>This is the <strong>log-likelihood function</strong> for \( n \) i.i.d. observations from the model \( f(x \mid \theta) \).</p>

  <h4>üß† Why Sum of Logs?</h4>
  <p>Because:</p>
  \[
  \begin{aligned}
  \text{Likelihood: } \mathcal{L}(\theta \mid x_1, \dots, x_n) &= \prod_{i=1}^n f(x_i \mid \theta) \\
  \Rightarrow \log \mathcal{L}(\theta \mid x_1, \dots, x_n) &= \sum_{i=1}^n \log f(x_i \mid \theta)
  \end{aligned}
  \]
  <p>Taking the log simplifies multiplication into summation.</p>

  <h4>üîß Score Function (Gradient of Log-Likelihood)</h4>
  <p>Now differentiate the log-likelihood with respect to \( \theta \):</p>
  \[
  \frac{\partial}{\partial \theta} L(\theta \mid x_1, \dots, x_n) = \sum_{i=1}^n \frac{\partial}{\partial \theta} \log f(x_i \mid \theta)
  \]
  <p>Using the chain rule:</p>
  \[
  = \sum_{i=1}^n \frac{1}{f(x_i \mid \theta)} \cdot \frac{\partial f(x_i \mid \theta)}{\partial \theta}
  \]
  <p>This is the <strong>score function</strong>, often denoted:</p>
  \[
  \nabla_\theta L(\theta \mid x_1, \dots, x_n)
  \]
  <p>‚úÖ Your symbolic expression is correct ‚Äî it's the score function for the full sample.</p>

  <h4>‚úÖ Summary</h4>
  \[
  \nabla_\theta L(\theta) = \sum_{i=1}^n \frac{ \frac{\partial}{\partial \theta} f(x_i \mid \theta) }{ f(x_i \mid \theta) } = \sum_{i=1}^n \frac{\partial}{\partial \theta} \log f(x_i \mid \theta)
  \]
  <p>This is crucial for:</p>
  <ul>
    <li><strong>Maximum Likelihood Estimation (MLE):</strong> Set score = 0 and solve for \( \theta \)</li>
    <li><strong>Fisher Information for \( n \) samples:</strong> \( \mathcal{I}_n(\theta) = n \mathcal{I}(\theta) \)</li>
    <li><strong>Asymptotic theory</strong> of MLEs (e.g., consistency, normality)</li>
  </ul>

  <h4>üìä Small Example: Normal Model with Known Variance</h4>
  <p>Suppose:</p>
  <ul>
    <li>\( X_1, \dots, X_n \sim \mathcal{N}(\mu, \sigma^2) \)</li>
    <li>\( \sigma^2 \) known; estimate \( \mu \)</li>
  </ul>

  <p>Then:</p>
  \[
  f(x_i \mid \mu) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left( -\frac{(x_i - \mu)^2}{2\sigma^2} \right)
  \]
  \[
  \log f(x_i \mid \mu) = -\frac{1}{2} \log(2\pi \sigma^2) - \frac{(x_i - \mu)^2}{2\sigma^2}
  \]

  <p>Summing over \( i \):</p>
  \[
  L(\mu) = \sum_{i=1}^n \log f(x_i \mid \mu) = -\frac{n}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^n (x_i - \mu)^2
  \]

  <p>Differentiating:</p>
  \[
  \frac{d}{d\mu} L(\mu) = \frac{1}{\sigma^2} \sum_{i=1}^n (x_i - \mu)
  \]

  <p>Set derivative = 0 for MLE:</p>
  \[
  \sum_{i=1}^n (x_i - \mu) = 0 \quad \Rightarrow \quad \mu = \bar{x}
  \]

  <p>‚úÖ So the MLE for \( \mu \) is the sample mean \( \bar{x} \).</p>
</section>

</div>





























<div class="glow-box" id="2.11">
  <section>
  <h4>üî∑ Newton‚ÄìRaphson for MLE: Likelihood Maximization</h4>
  <p>You're now discussing <strong>numerical optimization of the likelihood</strong> using the <strong>Newton‚ÄìRaphson method</strong>, one of the core techniques to compute <strong>Maximum Likelihood Estimators (MLEs)</strong>.</p>
  <p>We'll break this into four parts for clarity:</p>
  <hr>

  <h4>üîπ 1. Understanding the Graph of \( L(\theta) \) vs \( \theta \)</h4>
  <p>The graph of the log-likelihood function \( L(\theta) \) often looks like a smooth, concave curve. The peak of this curve corresponds to the MLE \( \hat{\theta} \).</p>

  <pre>
        ^
     L(Œ∏)
        |          /\
        |         /  \
        |        /    \
        |_______/______\________>
                    Œ∏ÃÇ
  </pre>

  <p>At the maximum, the slope \( \frac{d}{d\theta} L(\theta) \) is zero ‚Äî this is the <strong>first-order optimality condition</strong>.</p>

  <h4>üîß 2. Gradient Ascent (Steepest Ascent)</h4>
  <p>The update:</p>
  \[
  \hat{\theta}_{r+1} = \hat{\theta}_r + \eta_r \cdot \nabla_\theta L(\theta_r \mid x_1, \dots, x_n)
  \]
  <p>This is a <strong>gradient ascent step</strong>, where:</p>
  <ul>
    <li>\( \eta_r \) is a step size (learning rate)</li>
    <li>\( \nabla_\theta L(\theta) \) is the gradient (score function)</li>
    <li>You‚Äôre moving in the direction of increasing likelihood</li>
  </ul>
  <blockquote>This is <strong>not</strong> Newton‚ÄìRaphson yet ‚Äî just basic gradient ascent.</blockquote>

  <h4>üß† 3. Newton‚ÄìRaphson Update</h4>
  <p>Newton‚ÄìRaphson improves on gradient ascent by incorporating the second derivative:</p>
  <ul>
    <li><strong>Gradient:</strong> \( \nabla_\theta L(\theta) \)</li>
    <li><strong>Hessian:</strong> \( \nabla^2_\theta L(\theta) \)</li>
  </ul>

  <p>The update rule becomes:</p>
  \[
  \hat{\theta}_{r+1} = \hat{\theta}_r - \left[ \nabla^2_\theta L(\theta_r) \right]^{-1} \cdot \nabla_\theta L(\theta_r)
  \]

  <p>‚úÖ The <strong>minus sign</strong> reflects that for maximizing a concave function, you move <em>against</em> the curvature direction.</p>

  <h4>üìå What's the Intuition?</h4>
  <ul>
    <li>The <strong>first derivative</strong> tells you the direction to move</li>
    <li>The <strong>second derivative</strong> tells you how much to move (curvature)</li>
  </ul>

  <pre>
   ^
L(Œ∏)|         *
     |        ^
     |       /|\
     |      / | \    ‚Üê Newton step lands at the peak
     |_____/__|__\________>
               Œ∏
  </pre>

  <h4>üí° Newton vs Gradient Ascent</h4>
<table style="width: 100%; border-collapse: collapse; margin-top: 1em;">
  <thead style="background-color: #6effe0;color: black; box-shadow: 0 0 10px #58e181;">
    <tr>
      <th style="border: 1px solid #ccc; padding: 8px;">Method</th>
      <th style="border: 1px solid #ccc; padding: 8px;">Uses</th>
      <th style="border: 1px solid #ccc; padding: 8px;">Pros</th>
      <th style="border: 1px solid #ccc; padding: 8px;">Cons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="border: 1px solid #ccc; padding: 8px;">Gradient Ascent</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Gradient only</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Simple</td>
      <td style="border: 1px solid #ccc; padding: 8px;">May take many steps</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ccc; padding: 8px;">Newton‚ÄìRaphson</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Gradient + Hessian</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Quadratic convergence</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Requires second derivative</td>
    </tr>
  </tbody>
</table>


  <p>For well-behaved likelihoods (e.g., Normal), Newton‚ÄìRaphson can converge in just a few steps.</p>

  <h4>üî¢ Example: Normal Model with Known Variance</h4>
  <p>Suppose:</p>
  <ul>
    <li>\( X_1, \dots, X_n \sim \mathcal{N}(\mu, \sigma^2) \)</li>
    <li>\( \sigma^2 \) is known; find MLE for \( \mu \)</li>
  </ul>

  <p>Log-likelihood:</p>
  \[
  L(\mu) = -\frac{1}{2\sigma^2} \sum_{i=1}^n (x_i - \mu)^2 + \text{const}
  \]

  <p>Then:</p>
  <ul>
    <li>\( \nabla_\mu L = \frac{1}{\sigma^2} \sum (x_i - \mu) = \frac{n}{\sigma^2} (\bar{x} - \mu) \)</li>
    <li>\( \nabla^2_\mu L = -\frac{n}{\sigma^2} \)</li>
  </ul>

  <p>Newton‚ÄìRaphson update:</p>
  \[
  \mu_{r+1} = \mu_r - \left( -\frac{\sigma^2}{n} \right) \cdot \frac{n}{\sigma^2} (\bar{x} - \mu_r) = \mu_r + (\bar{x} - \mu_r) = \bar{x}
  \]

  <p>‚úÖ It converges in one step ‚Äî because the log-likelihood is quadratic!</p>

  <h4>‚úÖ Summary</h4>
  <ul>
    <li>You‚Äôre using <strong>gradient ascent</strong> to maximize \( L(\theta) \)</li>
    <li><strong>Newton‚ÄìRaphson</strong> is more efficient by using curvature (Hessian)</li>
    <li>It‚Äôs standard in MLE, logistic regression, Poisson models, etc.</li>
  </ul>
</section>

</div>





























<div class="glow-box" id="2.12">
  <section>
  <h3>On the Direction of Steepest Ascent:</h3>
  <h4>üî∑ 1. Why the Direction of Steepest Ascent?</h4>
  <p>Imagine the log-likelihood function \( L(\theta) \) as a <strong>landscape</strong> ‚Äî a smooth surface over the parameter space.<br>
  Your goal: <strong>reach the top (maximum likelihood estimate \( \hat{\theta} \))</strong>.</p>

  <p>At any point \( \theta_r \), the <strong>gradient</strong> \( \nabla_\theta L(\theta_r) \) is a vector that:</p>
  <ul>
    <li>Points in the direction where \( L(\theta) \) increases most rapidly.</li>
    <li>Has a <strong>magnitude</strong> equal to the rate of increase in that direction.</li>
  </ul>

  <p>So, to climb the hill toward the MLE, you step in the direction of the <strong>gradient</strong>:</p>
  \[
    \hat{\theta}_{r+1} = \hat{\theta}_r + \eta_r \cdot \nabla_\theta L(\theta_r)
  \]
  <p>Here, \( \eta_r > 0 \) is your <strong>step size</strong> ‚Äî how far you move in that direction.</p>

  <h4>üî∂ 2. What Makes Gradient the <em>Steepest</em> Direction?</h4>
  <p><strong>Let‚Äôs be precise:</strong></p>
  <p>Suppose you want to increase \( L(\theta) \) by moving a small distance \( \delta \theta \). The first-order change is:</p>
  \[
    \Delta L(\theta) \approx \nabla_\theta L(\theta)^\top \delta \theta
  \]
  <p>We want to choose \( \delta \theta \) of unit length (i.e., \( \| \delta \theta \| = 1 \)) that gives <strong>maximum increase</strong>:</p>
  \[
    \max_{\| \delta \theta \| = 1} \nabla_\theta L(\theta)^\top \delta \theta
  \]
  <p>The solution to this maximization is:</p>
  \[
    \delta \theta = \frac{ \nabla_\theta L(\theta) }{ \| \nabla_\theta L(\theta) \| }
  \]
  <p>i.e., move in the <strong>direction of the gradient</strong>. ‚úÖ</p>

  <h4>üìä Visual Intuition (2D Case)</h4>
  <p>Think of the log-likelihood surface like a hill in 3D.</p>
  <ul>
    <li>The <strong>gradient vector</strong> at your current point points <em>uphill</em> in the steepest direction.</li>
    <li>If you move orthogonally to the gradient, you stay at the same level (iso-likelihood curve).</li>
    <li>Moving against the gradient leads you <em>downhill</em> ‚Äî which you want to avoid during maximization.</li>
  </ul>

  <pre>
      ^
     /|\\         ‚Üê Gradient points this way
    / |
   /  |             Log-Likelihood surface
  *---‚Üí
Current Œ∏_r
  </pre>

  <h4>üîÅ Comparison with Newton‚ÄìRaphson</h4>
  <ul>
    <li><strong>Steepest ascent</strong>: always follows the direction of greatest immediate gain.</li>
    <li><strong>Newton‚ÄìRaphson</strong>: modifies the direction based on the <strong>curvature</strong>, sometimes avoiding overshooting or zigzagging.</li>
  </ul>

  <p>So, in practice:</p>
  <ul>
    <li><strong>Gradient ascent</strong> is more robust, especially when the curvature is poorly behaved or Hessians are hard to compute.</li>
    <li><strong>Newton‚ÄìRaphson</strong> is faster when curvature information is reliable and the function is well-behaved (e.g., Gaussian likelihood).</li>
  </ul>

  <h4>‚úÖ Summary</h4>
  <ul>
    <li>We prefer the direction of <strong>steepest ascent</strong> because it guarantees the fastest local increase in the log-likelihood.</li>
    <li>The <strong>gradient</strong> gives this direction.</li>
    <li>The <strong>step size</strong> \( \eta_r \) controls how aggressively we move ‚Äî too small = slow; too large = unstable.</li>
    <li>This approach is the foundation for many modern learning algorithms, including <strong>stochastic gradient ascent</strong> in MLE for big data or machine learning.</li>
  </ul>
</section>

</div>





























<div class="glow-box" id="2.13">
  <section>
  <h4>üî∑ Connecting Fisher Information with the Hessian Matrix</h4>
  <p>Now connecting <strong>Fisher‚Äôs Information Matrix</strong> with the <strong>Hessian matrix</strong> of the log-likelihood function.</p>
  <p>Let‚Äôs unpack this carefully and precisely.</p>

  <hr>

  <h4>üî∑ 1. Fisher Information Matrix (Multivariate Version)</h4>
  <p>Suppose \( \theta \in \mathbb{R}^k \) is a <strong>vector parameter</strong> and \( f(x \mid \theta) \) is a probability density function satisfying standard regularity conditions.</p>

  <p>Then, the <strong>Fisher Information Matrix</strong> is defined as:</p>
  \[
  \mathcal{I}(\theta) = \mathbb{E}_\theta \left[ \left( \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right)
  \left( \frac{\partial}{\partial \theta} \log f(x \mid \theta) \right)^\top \right]
  \]

  <ul>
    <li>This is a \( k \times k \) <strong>positive semi-definite matrix</strong>.</li>
    <li>It measures how much information the data carries about each component of \( \theta \), and how the components interact.</li>
  </ul>

  <hr>

  <h4>üî∂ 2. Alternative Definition Using the Hessian (Second Derivatives)</h4>
  <p>Under regularity conditions, the Fisher Information Matrix can also be written as the <strong>negative expected Hessian</strong> of the log-likelihood function:</p>
  \[
  \mathcal{I}(\theta) = - \mathbb{E}_\theta \left[ \frac{\partial^2}{\partial \theta \partial \theta^\top} \log f(x \mid \theta) \right]
  \]

  <p>‚úÖ This is what your note says:</p>
  <blockquote>
    \( \mathbb{E}\left( -\frac{ \partial^2 }{ \partial \theta \partial \theta^\top } \log f(x \mid \theta) \right) = \text{Fisher Information Matrix} \)
  </blockquote>

  <hr>

  <h4>üìå 3. What Is the Hessian Matrix?</h4>
  <p>The <strong>Hessian</strong> of a scalar-valued function \( L(\theta) \), where \( \theta \in \mathbb{R}^k \), is the matrix of <strong>second partial derivatives</strong>:</p>
  \[
  H(\theta) = \left[ \frac{ \partial^2 L(\theta) }{ \partial \theta_i \partial \theta_j } \right]_{i,j=1}^k
  \]

  <p>So for the <strong>log-likelihood</strong> function \( \log f(x \mid \theta) \), the Hessian is:</p>
  \[
  \frac{ \partial^2 }{ \partial \theta \partial \theta^\top } \log f(x \mid \theta)
  \]

  <p>It‚Äôs a \( k \times k \) symmetric matrix, assuming smoothness.</p>

  <hr>

  <h4>üî∑ 4. The (i,j)-th Element of Fisher Info = Expected Negative Hessian Entry</h4>
  <p>You correctly stated:</p>
  <blockquote>
    (i, j)-th element of the Fisher Information matrix is the (i, j)-th element of the expected negative Hessian of \( \log f(x \mid \theta) \)
  </blockquote>

  <p>In symbols:</p>
  \[
  [\mathcal{I}(\theta)]_{i,j} = - \mathbb{E}_\theta \left[ \frac{\partial^2}{\partial \theta_i \partial \theta_j} \log f(x \mid \theta) \right]
  \]

  <p>This captures the <strong>curvature</strong> of the likelihood in the \( (\theta_i, \theta_j) \) direction.</p>

  <hr>

  <h4>üß† Why Two Equivalent Definitions?</h4>
  <p>Because of the <strong>Fisher identity</strong>:</p>
  \[
  \mathcal{I}(\theta) = \mathbb{E}_\theta \left[ \nabla_\theta \log f(x \mid \theta) \cdot \nabla_\theta \log f(x \mid \theta)^\top \right] 
  = - \mathbb{E}_\theta \left[ \nabla^2_\theta \log f(x \mid \theta) \right]
  \]

  <p>Both are equal <strong>only under regularity conditions</strong>, where we‚Äôre allowed to exchange integration and differentiation.</p>

  <hr>

  <h4>‚úÖ Summary</h4>
  <table>
    <thead>
      <tr>
        <th>Quantity</th>
        <th>Meaning</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>\( \nabla_\theta \log f(x \mid \theta) \)</td>
        <td>Score function (gradient of log-likelihood)</td>
      </tr>
      <tr>
        <td>\( \nabla^2_\theta \log f(x \mid \theta) \)</td>
        <td>Hessian matrix (second derivatives)</td>
      </tr>
      <tr>
        <td>\( \mathcal{I}(\theta) \)</td>
        <td>Fisher Information Matrix</td>
      </tr>
      <tr>
        <td>\( [\mathcal{I}(\theta)]_{i,j} \)</td>
        <td>Expected negative second derivative of log-likelihood w.r.t \( \theta_i \) and \( \theta_j \)</td>
      </tr>
    </tbody>
  </table>
</section>

</div>































<div class="glow-box" id="2.14">
 <h4>üß≠ Overview</h4>
<p>You are essentially learning the <b>geometry and calculus behind MLE</b>:</p>
<ul>
  <li>When do we stop iterating for an estimate?</li>
  <li>How do we measure ‚Äúinformation‚Äù in the data?</li>
  <li>What are the limits of accuracy for unbiased estimators?</li>
</ul>

<hr>

<h4>1. ‚úÖ Stopping Criteria in Iterative Estimation</h4>
<p><b>üîÅ In iterative methods</b> (like Newton‚ÄìRaphson, gradient ascent), we update:</p>
<pre><code>Œ∏ÃÇ_{r+1} = Œ∏ÃÇ_r + Œ∑_r ‚ãÖ ‚àá<sub>Œ∏</sub> L(Œ∏ÃÇ_r)</code></pre>
<p>We stop when the estimate becomes stable:</p>
<pre><code>‚ÄñŒ∏ÃÇ<sub>r+1</sub> ‚àí Œ∏ÃÇ<sub>r</sub>‚Äñ‚ÇÇ &lt; Œµ</code></pre>
<p><b>‚úÖ Example:</b> If Œ∏ = (Œº, œÉ)<sup>T</sup>, then:</p>
<pre><code>‚ÄñŒ∏ÃÇ<sub>r+1</sub> ‚àí Œ∏ÃÇ<sub>r</sub>‚Äñ‚ÇÇ¬≤ = (ŒºÃÇ<sub>r+1</sub> ‚àí ŒºÃÇ<sub>r</sub>)¬≤ + (œÉÃÇ<sub>r+1</sub> ‚àí œÉÃÇ<sub>r</sub>)¬≤</code></pre>

<hr>

<h4>2. üìò Fisher Information Matrix ‚Ñê(Œ∏)</h4>
<pre><code>‚Ñê(Œ∏) = E[ ‚àí‚àÇ¬≤/‚àÇŒ∏ ‚àÇŒ∏·µó log f(x | Œ∏) ]</code></pre>
<p><b>üîé Intuition:</b></p>
<ul>
  <li>Very curved log-likelihood ‚áí precise estimate (low variance)</li>
  <li>Flat log-likelihood ‚áí uncertain estimate (high variance)</li>
</ul>
<pre><code>
       log L(Œ∏)
           ^
           |
   High    |     ____
   info    |   /    \
           |  /      \
           | /        \
   Low     |/          \___
           +-------------------> Œ∏
</code></pre>

<hr>

<h4>3. üßÆ Hessian Matrix H</h4>
<pre><code>H(Œ∏) = [ ‚àÇ¬≤L / ‚àÇŒ∏·µ¢‚àÇŒ∏‚±º ]</code></pre>
<ul>
  <li>Measures curvature of L(Œ∏)</li>
  <li>Scalar case: just d¬≤L/dŒ∏¬≤</li>
  <li>Vector Œ∏ ‚áí k√ók symmetric matrix</li>
</ul>
<p><b>üîÅ In Newton‚ÄìRaphson:</b></p>
<pre><code>Œ∏ÃÇ<sub>r+1</sub> = Œ∏ÃÇ<sub>r</sub> ‚àí H<sup>‚àí1</sup> ‚àá<sub>Œ∏</sub> L</code></pre>

<hr>

<h4>4. üîó Link Between Hessian and Fisher Information</h4>
<pre><code>‚Ñê(Œ∏) = E_Œ∏[‚àíH(Œ∏)] = E_Œ∏[‚àí‚àÇ¬≤/‚àÇŒ∏‚àÇŒ∏·µó log f(x | Œ∏)]</code></pre>
<p><b>‚úÖ Requires regularity conditions</b></p>

<p><b>For i.i.d. Data:</b></p>
<pre><code>X‚ÇÅ,‚Ä¶,X‚Çô ~ i.i.d. f(x | Œ∏)</code></pre>
<pre><code>
L(Œ∏) = ‚àë log f(x·µ¢ | Œ∏) ‚áí
‚Ñê(Œ∏) = n ‚ãÖ E[‚àí‚àÇ¬≤/‚àÇŒ∏‚àÇŒ∏·µó log f(x‚ÇÅ | Œ∏)]
</code></pre>

<p>So more data ‚áí higher curvature ‚áí better certainty</p>

<pre><code>
E[‚àí‚àÇ¬≤/‚àÇŒ∏‚àÇŒ∏·µó log f(x‚ÇÅ | Œ∏)] = Pre-sample Fisher Info
</code></pre>

<hr>

<h4>5. üéØ Cram√©r‚ÄìRao Lower Bound (CRLB)</h4>
<p><b>If Œ∏ÃÇ is unbiased:</b></p>
<pre><code>Var(Œ∏ÃÇ) ‚â• ‚Ñê<sup>‚àí1</sup>(Œ∏)</code></pre>
<p>In scalar case:</p>
<pre><code>Var(Œ∏ÃÇ) ‚â• 1 / ‚Ñê(Œ∏)</code></pre>
<ul>
  <li>CRLB is the theoretical lower bound on variance of unbiased estimators</li>
  <li>Attained when estimator is "efficient"</li>
</ul>

<hr>

<h4>6. üßæ Observed Information Matrix</h4>
<pre><code>ùí•(Œ∏) = ‚àíH = ‚àí‚àë ‚àÇ¬≤/‚àÇŒ∏‚àÇŒ∏·µó log f(x·µ¢ | Œ∏)</code></pre>
<p>Used in:</p>
<ul>
  <li>Newton-Raphson updates (actual curvature)</li>
  <li>MLE variance estimation:</li>
</ul>
<pre><code>VarÃÇ(Œ∏ÃÇ) ‚âà [ùí•(Œ∏ÃÇ)]<sup>‚àí1</sup></code></pre>

<hr>

<h4>‚úÖ Summary Table</h4>
<table>
  <thead>
    <tr>
      <th>Concept</th>
      <th>Formula</th>
      <th>Interpretation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Gradient (Score)</td>
      <td>‚àá<sub>Œ∏</sub> L(Œ∏)</td>
      <td>Direction of steepest ascent</td>
    </tr>
    <tr>
      <td>Hessian</td>
      <td>H(Œ∏) = ‚àÇ¬≤L / ‚àÇŒ∏ ‚àÇŒ∏·µó</td>
      <td>Curvature of log-likelihood</td>
    </tr>
    <tr>
      <td>Fisher Info</td>
      <td>‚Ñê(Œ∏) = E[‚àíH]</td>
      <td>Expected curvature</td>
    </tr>
    <tr>
      <td>Observed Info</td>
      <td>ùí•(Œ∏) = ‚àíH</td>
      <td>Actual curvature from data</td>
    </tr>
    <tr>
      <td>CRLB</td>
      <td>Var(Œ∏ÃÇ) ‚â• ‚Ñê<sup>‚àí1</sup>(Œ∏)</td>
      <td>Lower bound on estimator variance</td>
    </tr>
  </tbody>
</table>

<hr>
</div>





























<div class="glow-box" id="2.15">
  <section>
  <h4>üî∑ 1. Background: Newton‚ÄìRaphson in MLE</h4>
<p>Recall that for Maximum Likelihood Estimation (MLE), we want to <strong>maximize</strong> the log-likelihood function:</p>
<p>$$L(\theta) = \sum_{i=1}^n \log f(x_i \mid \theta)$$</p>
<p>The <strong>Newton‚ÄìRaphson update rule</strong> for finding the root of $\nabla_\theta L(\theta) = 0$ is:</p>
<p>$$\theta^{(r+1)} = \theta^{(r)} - \left[ H(\theta^{(r)}) \right]^{-1} \nabla_\theta L(\theta^{(r)})$$</p>
<ul>
  <li>$\nabla_\theta L(\theta)$ is the <strong>score function</strong></li>
  <li>$H(\theta) = \nabla_\theta^2 L(\theta)$ is the <strong>Hessian matrix</strong></li>
</ul>

<h4>üî∑ 2. Problem with Newton‚ÄìRaphson</h4>
<p>In practice, $H(\theta)$ may:</p>
<ul>
  <li>Be difficult to compute or invert</li>
  <li>Be <strong>non-invertible</strong> at some points</li>
  <li>Lead to <strong>unstable convergence</strong></li>
</ul>

<h4>üî∑ 3. Fisher‚Äôs Scoring: Motivation</h4>
<p>To solve these issues, we replace the <strong>observed Hessian</strong> \( H(\theta) \) with its <strong>expectation</strong>:</p>
<p>$$\mathcal{I}(\theta) = \mathbb{E}_\theta\left[-\nabla_\theta^2 L(\theta)\right]$$</p>
<p>This is the <strong>Fisher Information Matrix</strong>. It's often easier to compute and is <strong>positive semi-definite</strong>.</p>

<h4>üî∑ 4. Fisher‚Äôs Scoring Update Rule</h4>
<p>The update rule becomes:</p>
<p>$$\theta^{(r+1)} = \theta^{(r)} + \left[\mathcal{I}(\theta^{(r)})\right]^{-1} \nabla_\theta L(\theta^{(r)})$$</p>
<p>üîÅ Notice:</p>
<ul>
  <li>Update direction uses the <strong>gradient (score)</strong></li>
  <li>Scaled by <strong>inverse Fisher Information</strong>, not Hessian</li>
</ul>

<h4>üî∑ 5. Visualization: Geometric Insight</h4>
<p>Imagine you‚Äôre on a hill (log-likelihood surface):</p>
<ul>
  <li><strong>Gradient Ascent</strong>: step in steepest direction</li>
  <li><strong>Newton‚ÄìRaphson</strong>: adjusts for curvature (Hessian)</li>
  <li><strong>Fisher Scoring</strong>: uses <em>average curvature</em> ‚Äî smoother steps</li>
</ul>

<h4>üî∑ 6. Example: Bernoulli Distribution</h4>
<p>Let \( X_1, \dots, X_n \sim \text{Bern}(p)\)  where \( 0 &lt; p &lt; 1 \) </p>
<p><strong>Log-likelihood:</strong></p>
<p>$$L(p) = \sum_{i=1}^n \left[ x_i \log p + (1 - x_i)\log(1 - p) \right]$$</p>
<p><strong>Score function:</strong></p>
<p>$$\frac{dL}{dp} = \frac{n\bar{X}}{p} - \frac{n(1 - \bar{X})}{1 - p}$$</p>
<p><strong>Observed Information:</strong></p>
<p>$$H(p) = -\frac{n\bar{X}}{p^2} - \frac{n(1 - \bar{X})}{(1 - p)^2}$$</p>
<p><strong>Fisher Information:</strong></p>
<p>$$\mathcal{I}(p) = \frac{n}{p(1 - p)}$$</p>
<p><strong>Fisher Scoring update:</strong></p>
<p>$$p^{(r+1)} = p^{(r)} + \left[ \frac{n}{p^{(r)}(1 - p^{(r)})} \right]^{-1} \left( \frac{n\bar{X}}{p^{(r)}} - \frac{n(1 - \bar{X})}{1 - p^{(r)}} \right)$$</p>
<p><strong>Which simplifies to:</strong></p>
<p>$$p^{(r+1)} = \bar{X}$$</p>
<p>üéØ <strong>That‚Äôs the MLE!</strong> Fisher scoring converges to it in <em>one step</em> for Bernoulli.</p>

<h4>üî∑ 7. Comparison Table</h4>
<table style="width: 100%; border-collapse: collapse; margin-top: 1em;">
  <thead style="background-color: #6effe0; color: black; box-shadow: 0 0 10px #58e181;">
    <tr>
      <th style="border: 1px solid #ccc; padding: 8px;">Method</th>
      <th style="border: 1px solid #ccc; padding: 8px;">Uses</th>
      <th style="border: 1px solid #ccc; padding: 8px;">Stability</th>
      <th style="border: 1px solid #ccc; padding: 8px;">Convergence Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="border: 1px solid #ccc; padding: 8px;">Gradient Ascent</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Gradient only</td>
      <td style="border: 1px solid #ccc; padding: 8px;">May overshoot</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Slower</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ccc; padding: 8px;">Newton‚ÄìRaphson</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Gradient + Hessian</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Can be unstable</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Fast if Hessian good</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ccc; padding: 8px;">Fisher Scoring</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Gradient + Expected Hessian</td>
      <td style="border: 1px solid #ccc; padding: 8px;">More stable</td>
      <td style="border: 1px solid #ccc; padding: 8px;">Fast, smoother</td>
    </tr>
  </tbody>
</table>

    <h4>üî∑ 8. When to Use Fisher Scoring?</h4>
<p>‚úÖ Use it when:</p>
<ul>
  <li><strong>Likelihood function is well-behaved</strong> but observed Hessian is messy</li>
  <li>Working with <strong>GLMs</strong> ‚Äî Fisher scoring is standard for IRLS</li>
  <li>You need <strong>stable convergence</strong> with positive curvature</li>
</ul>
</section>
</div>




























</section>
<button class="prev-btn" onclick="location.href='wk1.html'"> ‚Üê Previous Section </button>

<button class="next-btn" onclick="location.href='wk3.html'">Next Section ‚Üí</button>

<footer>
  <p>&copy; 2025 Shaan | Built with purpose</p>
</footer>
<script>
MathJax = {
  tex: {
    inlineMath: [['\\(', '\\)']],
    displayMath: [['\\[', '\\]']],
    packages: {'[+]': ['ams']}   // üëà add AMS package for \boldsymbol
  }
};
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>

</body>
</html>

